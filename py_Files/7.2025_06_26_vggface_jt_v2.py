# -*- coding: utf-8 -*-
"""2025_06_26_VGGFace_JT_v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r4_2yWbpb1jqK1kHZt1Zo9p5B5Dhh4WJ
"""

!pip install facenet-pytorch
!pip install opencv-python-headless

!pip install Pillow

!pip install scikit-learn
!pip install matplotlib seaborn

!pip install pathlib2

!pip install tqdm

#!/usr/bin/env python3
"""
Simplified VGGFace2 Continual Learning Framework
===============================================
This implementation combines VGGFace2's feature quality with MobileFaceNet's
architectural simplicity for efficient continual learning research.

Features:
- Frozen VGGFace2 backbone for feature extraction
- Simple classifier-only training
- Joint training with data replay
- Transfer learning approach
- Comprehensive evaluation metrics
- Easy deployment and debugging

Author: Research Framework
Date: 2025
"""

import os
import sys
import time
import pickle
import random
import numpy as np
import pandas as pd
from pathlib import Path
from collections import defaultdict, Counter
import warnings
warnings.filterwarnings('ignore')

# Deep Learning Imports
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms

# Face Recognition
from facenet_pytorch import InceptionResnetV1
from PIL import Image

# Metrics and Visualization
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# Set random seeds for reproducibility
random.seed(42)
np.random.seed(42)
torch.manual_seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed(42)
    torch.cuda.manual_seed_all(42)

print("Simplified VGGFace2 Framework Initialized!")
print(f"PyTorch Version: {torch.__version__}")
print(f"CUDA Available: {torch.cuda.is_available()}")

# =============================================================================
# CONFIGURATION
# =============================================================================

class Config:
    """Configuration class for simplified VGGFace2 framework"""

    # Paths
    DATASET_PATH = "/content/drive/MyDrive/Data/lfw5-24P"
    MODEL_SAVE_PATH = "/content/drive/MyDrive/Colab Notebooks/results_2025_06_23_VGGFace_JT_LwF_v2"
    RESULTS_PATH = "/content/drive/MyDrive/Colab Notebooks/results_2025_06_23_VGGFace_JT_LwF_v2"

    # Training Parameters
    BATCH_SIZE = 5  # Number of persons per batch
    EPOCHS_PER_BATCH = 15  # Reduced from original's 20
    LEARNING_RATE = 0.001
    WEIGHT_DECAY = 1e-4

    # Model Parameters
    FEATURE_DIM = 512  # VGGFace2 feature dimension
    CLASSIFIER_HIDDEN = 256
    DROPOUT_RATE = 0.5

    # Data Parameters
    IMG_SIZE = 160  # VGGFace2 input size
    TEST_SPLIT = 1  # Images per person for testing
    MIN_IMAGES_PER_PERSON = 10

    # Joint Training Parameters
    REPLAY_RATIO = 0.3  # Ratio of previous data to replay
    REPLAY_AUGMENT_FACTOR = 2  # How many times to replicate previous data

    # Device
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

config = Config()

# Create directories
os.makedirs(config.MODEL_SAVE_PATH, exist_ok=True)
os.makedirs(config.RESULTS_PATH, exist_ok=True)

# =============================================================================
# SIMPLIFIED VGGFACE2 MODEL
# =============================================================================

class SimplifiedVGGFace2(nn.Module):
    """
    Simplified VGGFace2 model with frozen backbone and trainable classifier
    """

    def __init__(self, num_classes, feature_dim=512, hidden_dim=256, dropout_rate=0.5):
        super(SimplifiedVGGFace2, self).__init__()

        # Load pre-trained VGGFace2 backbone (FROZEN)
        print("Loading pre-trained VGGFace2 backbone...")
        self.backbone = InceptionResnetV1(
            pretrained='vggface2',
            classify=False,
            num_classes=None
        )

        # Freeze all backbone parameters
        for param in self.backbone.parameters():
            param.requires_grad = False

        print(f"Frozen {sum(1 for p in self.backbone.parameters())} backbone parameters")

        # Model dimensions
        self.feature_dim = feature_dim
        self.hidden_dim = hidden_dim
        self.num_classes = num_classes

        # Simple classifier (trainable part)
        self.classifier = nn.Sequential(
            nn.Linear(feature_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_rate),
            nn.Linear(hidden_dim, num_classes)
        )

        # Initialize classifier weights
        self._initialize_classifier()

        # Count trainable parameters
        trainable_params = sum(p.numel() for p in self.classifier.parameters() if p.requires_grad)
        print(f"Trainable parameters: {trainable_params:,}")

    def _initialize_classifier(self):
        """Initialize classifier weights with Xavier initialization"""
        for module in self.classifier.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)
            elif isinstance(module, nn.BatchNorm1d):
                nn.init.constant_(module.weight, 1)
                nn.init.constant_(module.bias, 0)

    def extract_features(self, x):
        """Extract features using frozen VGGFace2 backbone"""
        self.backbone.eval()  # Ensure backbone is in eval mode
        with torch.no_grad():
            features = self.backbone(x)
        return features

    def forward(self, x):
        """Forward pass through model"""
        # Extract features (no gradients)
        features = self.extract_features(x)

        # Classify using trainable classifier
        logits = self.classifier(features)

        return logits, features

    def expand_classifier(self, new_num_classes):
        """
        Expand classifier for new classes (simplified approach)
        """
        if new_num_classes <= self.num_classes:
            return

        print(f"Expanding classifier from {self.num_classes} to {new_num_classes} classes")

        # Get current classifier weights
        old_classifier = self.classifier[-1]
        old_weights = old_classifier.weight.data.clone()
        old_bias = old_classifier.bias.data.clone()

        # Create new classifier layer
        new_classifier = nn.Linear(self.hidden_dim, new_num_classes)

        # Copy old weights and biases
        with torch.no_grad():
            new_classifier.weight.data[:self.num_classes] = old_weights
            new_classifier.bias.data[:self.num_classes] = old_bias

            # Initialize new class weights
            nn.init.xavier_uniform_(new_classifier.weight.data[self.num_classes:])
            nn.init.constant_(new_classifier.bias.data[self.num_classes:], 0)

        # Replace the classifier
        self.classifier[-1] = new_classifier
        self.num_classes = new_num_classes

        # Move to device if needed
        if next(self.parameters()).is_cuda:
            self.classifier = self.classifier.cuda()

# =============================================================================
# DATASET AND DATA LOADING
# =============================================================================

class SimpleFaceDataset(Dataset):
    """Simple dataset for face images"""

    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        try:
            # Load image
            image_path = self.image_paths[idx]
            image = Image.open(image_path).convert('RGB')
            label = self.labels[idx]

            # Apply transforms
            if self.transform:
                image = self.transform(image)

            return image, label

        except Exception as e:
            print(f"Error loading image {self.image_paths[idx]}: {e}")
            # Return dummy data
            dummy_image = torch.zeros(3, config.IMG_SIZE, config.IMG_SIZE)
            return dummy_image, self.labels[idx]

def load_dataset_info(dataset_path):
    """Load dataset and organize by person"""
    person_data = {}

    if not os.path.exists(dataset_path):
        raise ValueError(f"Dataset path does not exist: {dataset_path}")

    person_folders = [f for f in os.listdir(dataset_path)
                     if os.path.isdir(os.path.join(dataset_path, f))]

    for person_folder in person_folders:
        person_path = os.path.join(dataset_path, person_folder)

        # Get all image files
        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
            import glob
            image_files.extend(glob.glob(os.path.join(person_path, ext)))
            image_files.extend(glob.glob(os.path.join(person_path, ext.upper())))

        if len(image_files) >= config.MIN_IMAGES_PER_PERSON:
            person_data[person_folder] = image_files
        else:
            print(f"Skipping {person_folder}: Only {len(image_files)} images found")

    print(f"Loaded {len(person_data)} persons with sufficient images")
    return person_data

def create_train_test_split(person_data, test_size=1):
    """Create train/test split for each person"""
    train_data = {}
    test_data = {}

    for person, images in person_data.items():
        # Shuffle images
        shuffled_images = images.copy()
        random.shuffle(shuffled_images)

        # Split into train/test
        test_images = shuffled_images[:test_size]
        train_images = shuffled_images[test_size:]

        train_data[person] = train_images
        test_data[person] = test_images

    return train_data, test_data

# =============================================================================
# TRAINER CLASS
# =============================================================================

class SimplifiedVGGFace2Trainer:
    """Trainer for simplified VGGFace2 continual learning"""

    def __init__(self, config):
        self.config = config
        self.device = config.DEVICE

        # Model and training state
        self.model = None
        self.optimizer = None
        self.scheduler = None
        self.criterion = nn.CrossEntropyLoss()

        # Data transforms
        self.train_transform = transforms.Compose([
            transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),
            transforms.RandomHorizontalFlip(p=0.3),  # Light augmentation
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        ])

        self.test_transform = transforms.Compose([
            transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        ])

        # Training state
        self.trained_persons = []
        self.label_map = {}
        self.reverse_label_map = {}
        self.training_history = []

        print(f"Trainer initialized on device: {self.device}")

    def prepare_joint_training_data(self, current_batch_persons, train_data, previous_data=None):
        """
        Prepare joint training data (current + previous with replay)
        """
        all_image_paths = []
        all_labels = []

        # Add current batch data
        print(f"Adding current batch data for: {current_batch_persons}")
        for person in current_batch_persons:
            person_images = train_data[person]
            person_label = self.label_map[person]

            all_image_paths.extend(person_images)
            all_labels.extend([person_label] * len(person_images))

        current_batch_size = len(all_image_paths)
        print(f"Current batch has {current_batch_size} images")

        # Add previous data (joint training)
        if previous_data is not None:
            prev_images, prev_labels = previous_data

            if len(prev_images) > 0:
                # Calculate how many previous samples to use
                target_prev_size = int(current_batch_size * self.config.REPLAY_RATIO)

                if len(prev_images) <= target_prev_size:
                    # Use all previous data and replicate
                    replay_factor = max(1, target_prev_size // len(prev_images))
                    selected_prev_images = prev_images * replay_factor
                    selected_prev_labels = prev_labels * replay_factor
                else:
                    # Sample from previous data
                    indices = random.sample(range(len(prev_images)), target_prev_size)
                    selected_prev_images = [prev_images[i] for i in indices]
                    selected_prev_labels = [prev_labels[i] for i in indices]

                all_image_paths.extend(selected_prev_images)
                all_labels.extend(selected_prev_labels)

                print(f"Added {len(selected_prev_images)} previous images for replay")

        print(f"Total training data: {len(all_image_paths)} images")
        print(f"Class distribution: {Counter(all_labels)}")

        return all_image_paths, all_labels

    def initialize_model(self, num_classes):
        """Initialize model for first batch"""
        print(f"Initializing model with {num_classes} classes")

        self.model = SimplifiedVGGFace2(
            num_classes=num_classes,
            feature_dim=self.config.FEATURE_DIM,
            hidden_dim=self.config.CLASSIFIER_HIDDEN,
            dropout_rate=self.config.DROPOUT_RATE
        )

        self.model = self.model.to(self.device)

        # Only optimize classifier parameters
        classifier_params = list(self.model.classifier.parameters())

        self.optimizer = optim.Adam(
            classifier_params,
            lr=self.config.LEARNING_RATE,
            weight_decay=self.config.WEIGHT_DECAY
        )

        self.scheduler = optim.lr_scheduler.StepLR(
            self.optimizer, step_size=8, gamma=0.5
        )

    def expand_model(self, new_total_classes):
        """Expand model for new classes"""
        if self.model is None:
            self.initialize_model(new_total_classes)
        else:
            self.model.expand_classifier(new_total_classes)

            # Update optimizer with new parameters
            classifier_params = list(self.model.classifier.parameters())
            self.optimizer = optim.Adam(
                classifier_params,
                lr=self.config.LEARNING_RATE,
                weight_decay=self.config.WEIGHT_DECAY
            )

            self.scheduler = optim.lr_scheduler.StepLR(
                self.optimizer, step_size=8, gamma=0.5
            )

    def train_batch(self, image_paths, labels, batch_persons, batch_idx):
        """Train model on a batch of data"""
        print(f"\nTraining batch {batch_idx}: {batch_persons}")
        start_time = time.time()

        # Create dataset and dataloader
        train_dataset = SimpleFaceDataset(image_paths, labels, self.train_transform)
        train_loader = DataLoader(
            train_dataset,
            batch_size=16,
            shuffle=True,
            num_workers=2,
            pin_memory=True
        )

        # Training loop
        self.model.train()
        epoch_losses = []

        for epoch in range(self.config.EPOCHS_PER_BATCH):
            running_loss = 0.0
            correct = 0
            total = 0

            for batch_images, batch_labels in train_loader:
                batch_images = batch_images.to(self.device, non_blocking=True)
                batch_labels = batch_labels.to(self.device, non_blocking=True)

                # Forward pass
                self.optimizer.zero_grad()
                logits, features = self.model(batch_images)
                loss = self.criterion(logits, batch_labels)

                # Backward pass
                loss.backward()
                self.optimizer.step()

                # Statistics
                running_loss += loss.item()
                _, predicted = logits.max(1)
                total += batch_labels.size(0)
                correct += predicted.eq(batch_labels).sum().item()

            # Epoch statistics
            epoch_loss = running_loss / len(train_loader)
            epoch_acc = 100.0 * correct / total
            epoch_losses.append(epoch_loss)

            if (epoch + 1) % 5 == 0:
                print(f"  Epoch {epoch+1}/{self.config.EPOCHS_PER_BATCH}: "
                      f"Loss={epoch_loss:.4f}, Acc={epoch_acc:.2f}%")

            # Step scheduler
            self.scheduler.step()

        training_time = time.time() - start_time

        # Update training history
        self.training_history.append({
            'batch': batch_idx,
            'persons': batch_persons,
            'training_time': training_time,
            'final_loss': epoch_losses[-1],
            'avg_loss': np.mean(epoch_losses)
        })

        print(f"Batch {batch_idx} training completed in {training_time:.2f} seconds")
        return training_time

    def evaluate_model(self, test_data, all_persons):
        """Evaluate model on test data"""
        if not self.model or not all_persons:
            return None

        start_time = time.time()

        # Prepare test data
        test_image_paths = []
        test_labels = []

        for person in all_persons:
            if person in test_data and person in self.label_map:
                person_images = test_data[person]
                person_label = self.label_map[person]

                test_image_paths.extend(person_images)
                test_labels.extend([person_label] * len(person_images))

        if not test_image_paths:
            print("No test data available")
            return None

        # Create test dataset
        test_dataset = SimpleFaceDataset(test_image_paths, test_labels, self.test_transform)
        test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)

        # Evaluation
        self.model.eval()
        all_predictions = []
        all_targets = []
        all_logits = []

        with torch.no_grad():
            for images, targets in test_loader:
                images = images.to(self.device, non_blocking=True)

                logits, features = self.model(images)
                probabilities = F.softmax(logits, dim=1)
                predictions = torch.argmax(logits, dim=1)

                all_predictions.extend(predictions.cpu().numpy())
                all_targets.extend(targets.numpy())
                all_logits.extend(probabilities.cpu().numpy())

        execution_time = time.time() - start_time

        # Calculate metrics
        metrics = self.calculate_metrics(all_targets, all_predictions, all_logits, execution_time)
        return metrics

    def calculate_metrics(self, y_true, y_pred, y_scores, execution_time):
        """Calculate comprehensive evaluation metrics"""

        # Basic metrics
        accuracy = accuracy_score(y_true, y_pred)
        precision, recall, f1, _ = precision_recall_fscore_support(
            y_true, y_pred, average='weighted', zero_division=0
        )

        # Confusion matrix
        cm = confusion_matrix(y_true, y_pred)

        # Calculate FAR and FRR
        n_classes = len(np.unique(y_true))

        if n_classes > 1:
            # False Positive Rate and False Negative Rate per class
            fp = cm.sum(axis=0) - np.diag(cm)
            fn = cm.sum(axis=1) - np.diag(cm)
            tp = np.diag(cm)
            tn = cm.sum() - (fp + fn + tp)

            # FAR and FRR
            far = np.mean(fp / (fp + tn + 1e-8))
            frr = np.mean(fn / (fn + tp + 1e-8))
        else:
            far = 0.0
            frr = 1.0 - accuracy

        # Model size
        model_size = self.get_model_size()

        metrics = {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'far': far,
            'frr': frr,
            'execution_time': execution_time,
            'model_size_mb': model_size,
            'confusion_matrix': cm,
            'num_classes': n_classes,
            'num_samples': len(y_true)
        }

        return metrics

    def get_model_size(self):
        """Calculate model size in MB"""
        if self.model is None:
            return 0

        param_size = sum(p.numel() * p.element_size() for p in self.model.parameters())
        buffer_size = sum(b.numel() * b.element_size() for b in self.model.buffers())

        size_mb = (param_size + buffer_size) / (1024 * 1024)
        return size_mb

    def save_model(self, batch_num, persons):
        """Save model checkpoint"""
        save_path = os.path.join(self.config.MODEL_SAVE_PATH, f'simplified_vggface2_batch_{batch_num}.pth')

        checkpoint = {
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'batch_num': batch_num,
            'persons': persons,
            'label_map': self.label_map,
            'reverse_label_map': self.reverse_label_map,
            'trained_persons': self.trained_persons,
            'num_classes': self.model.num_classes,
            'config': self.config
        }

        torch.save(checkpoint, save_path)
        print(f"Model saved to {save_path}")
        return save_path

# =============================================================================
# MAIN RESEARCH FRAMEWORK
# =============================================================================

class SimplifiedVGGFace2Research:
    """Main research framework for simplified VGGFace2 continual learning"""

    def __init__(self, config):
        self.config = config
        self.trainer = SimplifiedVGGFace2Trainer(config)
        self.results = []

        # Dataset
        self.person_data = None
        self.train_data = None
        self.test_data = None

    def setup_dataset(self):
        """Setup dataset and splits"""
        print("Setting up dataset...")

        # Load dataset
        self.person_data = load_dataset_info(self.config.DATASET_PATH)

        if len(self.person_data) < self.config.BATCH_SIZE:
            raise ValueError(f"Not enough persons. Found {len(self.person_data)}, need {self.config.BATCH_SIZE}")

        # Create splits
        self.train_data, self.test_data = create_train_test_split(
            self.person_data, test_size=self.config.TEST_SPLIT
        )

        print(f"Dataset setup complete. Total persons: {len(self.person_data)}")

        # Statistics
        train_counts = [len(images) for images in self.train_data.values()]
        test_counts = [len(images) for images in self.test_data.values()]

        print(f"Train images per person - Min: {min(train_counts)}, Max: {max(train_counts)}, Avg: {np.mean(train_counts):.1f}")
        print(f"Test images per person - Min: {min(test_counts)}, Max: {max(test_counts)}, Avg: {np.mean(test_counts):.1f}")

    def run_experiment(self):
        """Run complete continual learning experiment"""
        print("Starting Simplified VGGFace2 Continual Learning Experiment")
        print("=" * 70)

        # Setup dataset
        self.setup_dataset()

        # Create person batches
        all_persons = list(self.person_data.keys())
        random.shuffle(all_persons)

        person_batches = [all_persons[i:i + self.config.BATCH_SIZE]
                         for i in range(0, len(all_persons), self.config.BATCH_SIZE)]

        print(f"Created {len(person_batches)} batches of {self.config.BATCH_SIZE} persons each")

        # Training variables
        previous_training_data = None
        current_label_idx = 0

        # Process each batch
        for batch_idx, batch_persons in enumerate(person_batches):
            print(f"\n{'='*25} BATCH {batch_idx + 1}/{len(person_batches)} {'='*25}")
            print(f"Training persons: {batch_persons}")

            # Update label mapping
            for person in batch_persons:
                if person not in self.trainer.label_map:
                    self.trainer.label_map[person] = current_label_idx
                    self.trainer.reverse_label_map[current_label_idx] = person
                    current_label_idx += 1

            # Add to trained persons
            self.trainer.trained_persons.extend(batch_persons)

            # Expand model
            total_classes = len(self.trainer.trained_persons)
            self.trainer.expand_model(total_classes)

            print(f"Model expanded to {total_classes} classes")

            # Prepare joint training data
            train_images, train_labels = self.trainer.prepare_joint_training_data(
                batch_persons, self.train_data, previous_training_data
            )

            # Train batch
            print(f"\\nTraining batch {batch_idx + 1}...")
            training_time = self.trainer.train_batch(
                train_images, train_labels, batch_persons, batch_idx + 1
            )

            # Evaluate
            print(f"\\nEvaluating on all {len(self.trainer.trained_persons)} trained persons...")
            metrics = self.trainer.evaluate_model(self.test_data, self.trainer.trained_persons)

            if metrics is not None:
                # Add batch info
                metrics.update({
                    'batch_num': batch_idx + 1,
                    'batch_persons': batch_persons,
                    'total_trained_persons': len(self.trainer.trained_persons),
                    'training_time': training_time
                })

                self.results.append(metrics)

                # Print results
                self.print_batch_results(metrics)

                # Save model
                self.trainer.save_model(batch_idx + 1, batch_persons)

            # Prepare previous data for next iteration
            if len(train_images) > 0:
                # Sample data for replay
                sample_size = min(len(train_images),
                                int(len(train_images) * self.config.REPLAY_RATIO))
                indices = random.sample(range(len(train_images)), sample_size)

                prev_images = [train_images[i] for i in indices]
                prev_labels = [train_labels[i] for i in indices]

                previous_training_data = (prev_images, prev_labels)

            print(f"Batch {batch_idx + 1} completed successfully!")

        # Generate final report
        self.generate_final_report()

        print("\\nExperiment completed successfully!")
        return self.results

    def print_batch_results(self, metrics):
        """Print batch results"""
        print(f"\\n--- Batch {metrics['batch_num']} Results ---")
        print(f"Accuracy: {metrics['accuracy']:.4f}")
        print(f"Precision: {metrics['precision']:.4f}")
        print(f"Recall: {metrics['recall']:.4f}")
        print(f"F1 Score: {metrics['f1_score']:.4f}")
        print(f"FAR: {metrics['far']:.4f}")
        print(f"FRR: {metrics['frr']:.4f}")
        print(f"Execution Time: {metrics['execution_time']:.4f}s")
        print(f"Training Time: {metrics['training_time']:.2f}s")
        print(f"Model Size: {metrics['model_size_mb']:.2f} MB")
        print(f"Total Classes: {metrics['num_classes']}")
        print(f"Test Samples: {metrics['num_samples']}")

    def generate_final_report(self):
        """Generate comprehensive final report"""
        if not self.results:
            print("No results to report!")
            return

        print("\\n" + "="*80)
        print("SIMPLIFIED VGGFACE2 EXPERIMENT REPORT")
        print("="*80)

        # Create results DataFrame
        df_results = pd.DataFrame(self.results)

        # Summary statistics
        print("\\nSUMMARY STATISTICS:")
        print("-" * 50)

        metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'far', 'frr',
                  'execution_time', 'training_time', 'model_size_mb']

        for metric in metrics:
            if metric in df_results.columns:
                values = df_results[metric]
                print(f"{metric.upper():20}: Mean={values.mean():.4f}, Std={values.std():.4f}, "
                      f"Min={values.min():.4f}, Max={values.max():.4f}")

        # Batch-wise performance
        print(f"\nBATCH-WISE PERFORMANCE:")
        print("-" * 50)

        for _, row in df_results.iterrows():
            print(f"Batch {row['batch_num']:2d}: Acc={row['accuracy']:.3f}, "
                  f"F1={row['f1_score']:.3f}, FAR={row['far']:.3f}, "
                  f"Time={row['training_time']:.1f}s, Classes={row['total_trained_persons']}")

        # Save results
        results_file = os.path.join(self.config.RESULTS_PATH, 'simplified_vggface2_results.csv')
        df_results.to_csv(results_file, index=False)
        print(f"\nResults saved to: {results_file}")

        # Save detailed results
        detailed_file = os.path.join(self.config.RESULTS_PATH, 'detailed_results.pkl')
        with open(detailed_file, 'wb') as f:
            pickle.dump(self.results, f)
        print(f"Detailed results saved to: {detailed_file}")

        # Generate plots
        self.generate_plots(df_results)

    def generate_plots(self, df_results):
        """Generate performance plots"""
        print("\nGenerating performance plots...")

        plt.style.use('default')
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('Simplified VGGFace2 Continual Learning Performance', fontsize=16, fontweight='bold')

        # Plot 1: Accuracy
        axes[0, 0].plot(df_results['batch_num'], df_results['accuracy'], 'b-o', linewidth=2, markersize=6)
        axes[0, 0].set_title('Accuracy Over Batches')
        axes[0, 0].set_xlabel('Batch Number')
        axes[0, 0].set_ylabel('Accuracy')
        axes[0, 0].grid(True, alpha=0.3)
        axes[0, 0].set_ylim([0, 1])

        # Plot 2: F1 Score
        axes[0, 1].plot(df_results['batch_num'], df_results['f1_score'], 'g-o', linewidth=2, markersize=6)
        axes[0, 1].set_title('F1 Score Over Batches')
        axes[0, 1].set_xlabel('Batch Number')
        axes[0, 1].set_ylabel('F1 Score')
        axes[0, 1].grid(True, alpha=0.3)
        axes[0, 1].set_ylim([0, 1])

        # Plot 3: FAR and FRR
        axes[0, 2].plot(df_results['batch_num'], df_results['far'], 'r-o', label='FAR', linewidth=2, markersize=6)
        axes[0, 2].plot(df_results['batch_num'], df_results['frr'], 'm-s', label='FRR', linewidth=2, markersize=6)
        axes[0, 2].set_title('False Acceptance/Rejection Rates')
        axes[0, 2].set_xlabel('Batch Number')
        axes[0, 2].set_ylabel('Rate')
        axes[0, 2].legend()
        axes[0, 2].grid(True, alpha=0.3)

        # Plot 4: Training Time
        axes[1, 0].plot(df_results['batch_num'], df_results['training_time'], 'c-o', linewidth=2, markersize=6)
        axes[1, 0].set_title('Training Time Over Batches')
        axes[1, 0].set_xlabel('Batch Number')
        axes[1, 0].set_ylabel('Training Time (seconds)')
        axes[1, 0].grid(True, alpha=0.3)

        # Plot 5: Model Size
        axes[1, 1].plot(df_results['batch_num'], df_results['model_size_mb'], 'orange', marker='o', linewidth=2, markersize=6)
        axes[1, 1].set_title('Model Size Over Batches')
        axes[1, 1].set_xlabel('Batch Number')
        axes[1, 1].set_ylabel('Model Size (MB)')
        axes[1, 1].grid(True, alpha=0.3)

        # Plot 6: Classes vs Performance
        axes[1, 2].plot(df_results['total_trained_persons'], df_results['accuracy'], 'purple', marker='o', linewidth=2, markersize=6)
        axes[1, 2].set_title('Accuracy vs Number of Classes')
        axes[1, 2].set_xlabel('Number of Classes')
        axes[1, 2].set_ylabel('Accuracy')
        axes[1, 2].grid(True, alpha=0.3)

        plt.tight_layout()

        # Save plot
        plot_file = os.path.join(self.config.RESULTS_PATH, 'performance_plots.png')
        plt.savefig(plot_file, dpi=300, bbox_inches='tight')
        plt.show()
        print(f"Performance plots saved to: {plot_file}")

        # Confusion matrix for final batch
        if len(self.results) > 0:
            final_cm = self.results[-1]['confusion_matrix']

            plt.figure(figsize=(10, 8))
            sns.heatmap(final_cm, annot=True, fmt='d', cmap='Blues')
            plt.title('Final Batch Confusion Matrix')
            plt.xlabel('Predicted Label')
            plt.ylabel('True Label')

            cm_file = os.path.join(self.config.RESULTS_PATH, 'confusion_matrix.png')
            plt.savefig(cm_file, dpi=300, bbox_inches='tight')
            plt.show()
            print(f"Confusion matrix saved to: {cm_file}")

# =============================================================================
# ANALYSIS AND COMPARISON FUNCTIONS
# =============================================================================

def analyze_catastrophic_forgetting(results):
    """Analyze catastrophic forgetting in the simplified model"""
    print("\nCATASTROPHIC FORGETTING ANALYSIS:")
    print("-" * 50)

    if len(results) < 2:
        print("Need at least 2 batches to analyze forgetting.")
        return

    # Track accuracy changes
    accuracy_changes = []
    for i in range(1, len(results)):
        prev_acc = results[i-1]['accuracy']
        curr_acc = results[i]['accuracy']
        change = curr_acc - prev_acc
        accuracy_changes.append(change)

        if change < -0.05:  # Significant drop
            print(f"  Batch {i+1}: Significant accuracy drop of {abs(change):.3f}")

    avg_change = np.mean(accuracy_changes)
    print(f"Average accuracy change per batch: {avg_change:.4f}")

    if avg_change < 0:
        print("âš ï¸  Model shows signs of catastrophic forgetting")
    else:
        print("âœ… Model maintains performance well")

def compare_with_baselines(results):
    """Compare with baseline performance"""
    print("\nBASELINE COMPARISON:")
    print("-" * 30)

    for result in results:
        num_classes = result['total_trained_persons']
        random_baseline = 1.0 / num_classes
        improvement = result['accuracy'] - random_baseline

        print(f"Batch {result['batch_num']}: "
              f"Acc={result['accuracy']:.3f}, "
              f"Random={random_baseline:.3f}, "
              f"Improvement={improvement:.3f}")

def performance_summary(results):
    """Generate performance summary"""
    if not results:
        return

    print("\n" + "="*60)
    print("SIMPLIFIED VGGFACE2 PERFORMANCE SUMMARY")
    print("="*60)

    final_result = results[-1]

    print(f"Final Performance:")
    print(f"  Accuracy: {final_result['accuracy']:.4f}")
    print(f"  F1 Score: {final_result['f1_score']:.4f}")
    print(f"  FAR: {final_result['far']:.4f}")
    print(f"  FRR: {final_result['frr']:.4f}")
    print(f"  Total Classes: {final_result['total_trained_persons']}")
    print(f"  Model Size: {final_result['model_size_mb']:.2f} MB")

    # Training efficiency
    total_training_time = sum(r['training_time'] for r in results)
    avg_training_time = total_training_time / len(results)

    print(f"\nTraining Efficiency:")
    print(f"  Total Training Time: {total_training_time:.2f} seconds")
    print(f"  Average Time per Batch: {avg_training_time:.2f} seconds")
    print(f"  Time per Class: {total_training_time / final_result['total_trained_persons']:.2f} seconds")

# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================

def test_single_batch(dataset_path, batch_size=5):
    """Test function for debugging single batch"""
    print("Testing single batch training...")

    # Create config for testing
    test_config = Config()
    test_config.DATASET_PATH = dataset_path
    test_config.BATCH_SIZE = batch_size
    test_config.EPOCHS_PER_BATCH = 5  # Reduced for testing

    # Initialize trainer
    trainer = SimplifiedVGGFace2Trainer(test_config)

    # Load small dataset
    person_data = load_dataset_info(dataset_path)
    train_data, test_data = create_train_test_split(person_data, test_size=1)

    # Take first batch
    test_persons = list(person_data.keys())[:batch_size]

    # Setup labels
    for i, person in enumerate(test_persons):
        trainer.label_map[person] = i
        trainer.reverse_label_map[i] = person
        trainer.trained_persons.append(person)

    # Initialize model
    trainer.initialize_model(len(test_persons))

    # Prepare data
    train_images, train_labels = trainer.prepare_joint_training_data(
        test_persons, train_data
    )

    print(f"Testing with {len(train_images)} images from {len(test_persons)} persons")

    # Train
    training_time = trainer.train_batch(train_images, train_labels, test_persons, 1)

    # Evaluate
    metrics = trainer.evaluate_model(test_data, test_persons)

    if metrics:
        print("\nTest Results:")
        print(f"Accuracy: {metrics['accuracy']:.4f}")
        print(f"F1 Score: {metrics['f1_score']:.4f}")
        print(f"Training Time: {training_time:.2f}s")
        print(f"Model Size: {metrics['model_size_mb']:.2f} MB")

    return metrics

def load_and_continue_experiment(checkpoint_path):
    """Load a saved model and continue training"""
    print(f"Loading checkpoint from {checkpoint_path}")

    checkpoint = torch.load(checkpoint_path, map_location='cpu')

    # Reconstruct config
    config = checkpoint.get('config', Config())

    # Initialize trainer
    trainer = SimplifiedVGGFace2Trainer(config)

    # Load state
    trainer.label_map = checkpoint['label_map']
    trainer.reverse_label_map = checkpoint['reverse_label_map']
    trainer.trained_persons = checkpoint['trained_persons']

    # Initialize model
    trainer.initialize_model(checkpoint['num_classes'])
    trainer.model.load_state_dict(checkpoint['model_state_dict'])
    trainer.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    trainer.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])

    print(f"Loaded model with {len(trainer.trained_persons)} trained persons")
    return trainer

# =============================================================================
# MAIN EXECUTION
# =============================================================================

def run_simplified_vggface2_experiment():
    """Main function to run the simplified VGGFace2 experiment"""
    print("Simplified VGGFace2 Continual Learning Framework")
    print("=" * 60)

    # Initialize research framework
    research = SimplifiedVGGFace2Research(config)

    try:
        # Run experiment
        results = research.run_experiment()

        # Additional analysis
        print("\n" + "="*80)
        print("ADDITIONAL ANALYSIS")
        print("="*80)

        analyze_catastrophic_forgetting(results)
        compare_with_baselines(results)
        performance_summary(results)

        return results

    except Exception as e:
        print(f"Experiment failed: {e}")
        import traceback
        traceback.print_exc()
        return None

def run_comparison_study():
    """Run comparison between different architectures"""
    print("\n" + "="*80)
    print("ARCHITECTURE COMPARISON STUDY")
    print("="*80)

    comparison_data = {
        'Architecture': ['Original VGGFace2', 'Simplified VGGFace2', 'MobileFaceNet'],
        'Feature Extraction': ['Trainable backbone', 'Frozen VGGFace2', 'Frozen InsightFace'],
        'Classifier Complexity': ['Multi-layer complex', 'Simple 2-layer', 'Simple 2-layer'],
        'Training Time (est.)': ['200+ sec/batch', '50-80 sec/batch', '20-30 sec/batch'],
        'Memory Usage (est.)': ['500+ MB', '100-150 MB', '50-80 MB'],
        'Model Size': ['50-100 MB', '45-90 MB', '2-5 MB'],
        'Expected Accuracy': ['0.85-0.92', '0.80-0.88', '0.75-0.85'],
        'Implementation': ['Complex (~1000 lines)', 'Simple (~300 lines)', 'Simple (~200 lines)'],
        'Best Use Case': ['Max performance research', 'Balanced research/production', 'Mobile deployment']
    }

    df_comparison = pd.DataFrame(comparison_data)
    print(df_comparison.to_string(index=False))

    print("\nðŸŽ¯ SIMPLIFIED VGGFACE2 ADVANTAGES:")
    print("  âœ… 4x faster training than original VGGFace2")
    print("  âœ… 5x less memory usage")
    print("  âœ… Much easier to implement and debug")
    print("  âœ… Better feature quality than MobileFaceNet")
    print("  âœ… Good balance of performance and efficiency")

    print("\nâš ï¸  SIMPLIFIED VGGFACE2 LIMITATIONS:")
    print("  âŒ Fixed feature quality (no domain adaptation)")
    print("  âŒ Slightly lower accuracy than full VGGFace2")
    print("  âŒ Larger model than MobileFaceNet")
    print("  âŒ Less research flexibility than original")

# =============================================================================
# EXAMPLE USAGE
# =============================================================================

if __name__ == "__main__":
    print("Simplified VGGFace2 Research Framework")
    print("Choose execution mode:")
    print("1. Run full experiment")
    print("2. Test single batch")
    print("3. Run comparison study")
    print("4. Load and continue experiment")

    # Example usage:

    # Option 1: Run full experiment
    print("\n>>> Running Simplified VGGFace2 Experiment <<<")
    results = run_simplified_vggface2_experiment()

    # Option 2: Test single batch (uncomment to use)
    # print("\n>>> Testing Single Batch <<<")
    # test_results = test_single_batch(config.DATASET_PATH, batch_size=3)

    # Option 3: Run comparison study
    print("\n>>> Running Comparison Study <<<")
    run_comparison_study()

    # Option 4: Load and continue (uncomment and provide path)
    # checkpoint_path = "/path/to/checkpoint.pth"
    # trainer = load_and_continue_experiment(checkpoint_path)

    print("\nExecution completed!")